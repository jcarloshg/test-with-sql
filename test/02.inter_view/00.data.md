As a Senior Backend Lead, I look for candidates who don't just "write queries" but understand how the database engine executes them. I want to see that you think about cost, scalability, and maintainability.

Here is your high-impact study guide.

---

### Tier 1: Essential Logic (The Foundation)

_You cannot pass the interview without mastering these. These test your ability to filter and manipulate data correctness._

#### 1. Order of Execution

Most candidates think SQL runs top-to-bottom. It doesn't.

- **Concept:** The engine processes clauses in this order: `FROM` -> `JOIN` -> `WHERE` -> `GROUP BY` -> `HAVING` -> `SELECT` -> `ORDER BY` -> `LIMIT`.
- **Why it matters:** This explains why you can't use a window function in a `WHERE` clause or an alias defined in `SELECT` inside a `GROUP BY`.
- **Interviewer's Lens / Red Flag:** Trying to filter an aggregate result (like `COUNT(*) > 5`) inside a `WHERE` clause. This shows a fundamental misunderstanding of the aggregation pipeline.

#### 2. `WHERE` vs. `HAVING`

- **Concept:** `WHERE` filters rows _before_ aggregation. `HAVING` filters groups _after_ aggregation.
- **Interviewer's Lens / Red Flag:** Using `HAVING` to filter non-aggregated columns (e.g., `HAVING user_id = 5`). While some DBs allow it, itâ€™s inefficient because rows shouldn't even enter the grouping stage if they aren't needed.

#### 3. JOIN Nuances (Inner, Left, Right, Full, Cross)

- **Concept:** Understanding set theory. Knowing that a `LEFT JOIN` preserves all records from the left table even if there is no match on the right (resulting in `NULL`s).
- **Interviewer's Lens / Red Flag:** Creating an accidental **Cartesian Product** (Cross Join) by missing a join condition. Also, filtering a `LEFT JOIN`'s right-side table in the `WHERE` clause effectively turns it into an `INNER JOIN` (because `NULL` fails the filter).

**ðŸ† Tier 1 Challenge Question:**

> "Write a query to find all users who have made more than 3 orders in the last month, but exclude users whose account status is 'banned'."

```sql
SELECT u.user_id, COUNT(o.id) as order_count
FROM users u
JOIN orders o ON u.id = o.user_id
WHERE u.status != 'banned'              -- Filter rows BEFORE grouping
  AND o.created_at > NOW() - INTERVAL '1 month'
GROUP BY u.user_id
HAVING COUNT(o.id) > 3;                 -- Filter groups AFTER grouping

```

---

### Tier 2: Advanced Querying (Analytical SQL)

_This separates Junior devs from Seniors. This tests your ability to solve complex business logic without resorting to fetching all data into Python/Node.js to process it._

#### 1. Window Functions (`OVER`, `PARTITION BY`)

- **Concept:** Performing calculations across a set of table rows that are somehow related to the current row, _without_ collapsing them into a single output row like `GROUP BY` does.
- **Key Functions:** `ROW_NUMBER()`, `RANK()`, `DENSE_RANK()`, `LEAD()`, `LAG()`.
- **Interviewer's Lens / Red Flag:** Solving a "top 3 items per category" problem using a complex self-join or subquery instead of a simple `RANK()`.

#### 2. CTEs (Common Table Expressions) vs. Subqueries

- **Concept:** Using `WITH` clauses to define temporary result sets.
- **Why it matters:** CTEs make complex logic readable. Subqueries (especially nested ones) are "write-only" codeâ€”hard to read and debug.
- **Interviewer's Lens / Red Flag:** Nesting 3+ layers of subqueries. If I have to spend 5 minutes decoding your indentation to understand the logic, it's a "No."

#### 3. Recursive CTEs

- **Concept:** A CTE that references itself. Essential for hierarchical data (e.g., Org charts, Comment threads, Category trees).

**ðŸ† Tier 2 Challenge Question:**

> "Given a table of `employee_salaries` (dept_id, employee_id, salary), write a query to return the top 3 earners per department, including ties."

```sql
WITH RankedSalaries AS (
    SELECT
        dept_id,
        employee_id,
        salary,
        -- DENSE_RANK includes ties and doesn't skip numbers (1, 1, 2)
        DENSE_RANK() OVER (PARTITION BY dept_id ORDER BY salary DESC) as rank_num
    FROM employee_salaries
)
SELECT * FROM RankedSalaries
WHERE rank_num <= 3;

```

---

### Tier 3: Performance & Architecture (The Engine)

_This is the "Lead" territory. I am testing if you can design systems that won't crash when we scale to 10 million users._

#### 1. Indexing Strategies

- **Concept:** B-Trees (default) vs. Hash Indexes vs. GIN (for JSONB).
- **Key Insight:** Indexes speed up Reads but slow down Writes (INSERT/UPDATE/DELETE).
- **Composite Indexes:** Order matters! If you have an index on `(A, B)`, it works for queries on `A` and `A+B`, but _not_ for queries on `B` alone.
- **Interviewer's Lens / Red Flag:** Suggesting we "index every column" to make it fast. This kills write performance.

#### 2. `EXPLAIN ANALYZE` & Execution Plans

- **Concept:** Reading the query plan to identify bottlenecks.
- **Keywords to watch:** "Seq Scan" (Full Table Scan - bad on large tables), "Index Scan" (Good), "Hash Join" vs "Nested Loop".
- **Interviewer's Lens / Red Flag:** Not knowing what an execution plan is. If you can't debug a slow query, you can't own a service.

#### 3. ACID Properties & Isolation Levels

- **Concept:** Atomicity (All or nothing), Consistency, Isolation, Durability.
- **Isolation Levels:**
- _Read Committed:_ (Default in Postgres) You see data once it's committed.
- _Serializable:_ Strict, prevents race conditions but hurts concurrency.

- **Interviewer's Lens / Red Flag:** Not understanding "Dirty Reads" or "Phantom Reads." Thinking that transactions "magically" solve all race conditions without considering isolation levels.

**ðŸ† Tier 3 Challenge Question:**

> "We have a query searching for users by `last_name` and `age` that is taking 5 seconds to run on a 10M row table. The current index is on `(age, last_name)`. Why might it be slow if we search `WHERE last_name = 'Smith'`, and how would you fix it?"

- **Answer:** The current index is a **Composite Index** on `(age, last_name)`. B-Trees are traversed left-to-right. If we filter _only_ by `last_name` (the second column), the engine cannot use the index effectively (or at all).
- **Fix:**

1. Create a separate index on `last_name`.
2. Or, change the query to include `age` if possible.
3. Or, flip the composite index to `(last_name, age)` if `last_name` is queried more frequently (Cardinality also plays a role here).
